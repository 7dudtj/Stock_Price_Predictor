{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fc6d0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "279dd262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n기본적인 code들은 영서님과 제가 업로드한 code를 이용해서 구현했습니다.\\n우선, 사용할 모델과 학습 데이터셋을 결정하시고 나서 해당 code를 수정해서 돌리면 됩니다.\\n해당 code는 ./Frame./test_codes./모델_데이터셋.ipynb 형태로 저장해서 돌리시면 됩니다.\\n\\n해당 모델은 xgboost로 월~금의 데이터를 기반으로 다음주 월, 화~월의 데이터로 화요일의 종가를 예측합니다.\\nlearning rate를 적절히 조정하면 4.345정도의 결과값을 보입니다.\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########사용법#########\n",
    "\"\"\"\n",
    "기본적인 code들은 영서님과 제가 업로드한 code를 이용해서 구현했습니다.\n",
    "우선, 사용할 모델과 학습 데이터셋을 결정하시고 나서 해당 code를 수정해서 돌리면 됩니다.\n",
    "해당 code는 ./Frame./test_codes./모델_데이터셋.ipynb 형태로 저장해서 돌리시면 됩니다.\n",
    "\n",
    "해당 모델은 xgboost로 월~금의 데이터를 기반으로 다음주 월, 화~월의 데이터로 화요일의 종가를 예측합니다.\n",
    "learning rate를 적절히 조정하면 4.345정도의 결과값을 보입니다.\n",
    "\"\"\"\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "41e90671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적으로 사용하는 함수들\n",
    "# columns rename function\n",
    "def cols_rename(data_set, target_name):\n",
    "    for i in data_set.columns:\n",
    "        if i == 'Date':\n",
    "            pass\n",
    "        else:\n",
    "            data_set.rename(columns={i:target_name+'_'+i}, inplace=True)\n",
    "    return data_set\n",
    "# columns rename function which has integer column name\n",
    "def cols_int_rename(data_set, target_name):\n",
    "    for i in data_set.columns:\n",
    "        if i == 'Date':\n",
    "            pass\n",
    "        else:\n",
    "            data_set.rename(columns={i:target_name+'_'+str(i)}, inplace=True)\n",
    "    return data_set\n",
    "# column rename function\n",
    "def col_rename(data_set, name_from, name_to):\n",
    "    for i in data_set.columns:\n",
    "        if i != name_from:\n",
    "            pass\n",
    "        else:\n",
    "            data_set.rename(columns={i:name_to}, inplace=True)\n",
    "    return data_set\n",
    "# function for adjusting friday to sunday data as new friday data\n",
    "def weekendToFriday(target, idx, col, returnType): # idx: Friday\n",
    "    if (returnType == 'intType'):\n",
    "        target.loc[idx, col] = (target.loc[idx, col]//7)*1 + (target.loc[idx+1, col]//7)*2 + (target.loc[idx+2, col]//7)*4\n",
    "    elif (returnType == 'floatType'):\n",
    "        target.loc[idx, col] = (target.loc[idx, col]/7)*1 + (target.loc[idx+1, col]/7)*2 + (target.loc[idx+2, col]/7)*4\n",
    "    return target.loc[idx, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d5957e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#세팅해야 하는 변수들\n",
    "\n",
    "# 데이터 수집 기간 설정\n",
    "#start_date = '20200106'\n",
    "start_date = '20140106'\n",
    "#start_date = '20201019'\n",
    "end_date = '20220520'\n",
    "\n",
    "# 기본적인 data를 불러오는 folder path\n",
    "path = '../data'\n",
    "list_name = 'stock_list.csv'\n",
    "sample_name = 'sample_submission.csv'\n",
    "\n",
    "stock_list = pd.read_csv(os.path.join(path, list_name))\n",
    "\n",
    "# 호용님 code에 유사하게 사용\n",
    "stock_list = stock_list.sort_values(by=['종목코드'])\n",
    "# 없는 것들은 삭제: 031390 ,036490\n",
    "stock_list.drop(stock_list[stock_list['종목코드']==31390].index,inplace=True)\n",
    "stock_list.drop(stock_list[stock_list['종목코드']==36490].index,inplace=True)\n",
    "stock_list['종목코드'] = stock_list['종목코드'].apply(lambda x : str(x).zfill(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "723ed758",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# 학습시킬 data를 선정하는 code 입니다\n",
    "######################################\n",
    "\n",
    "# make business_days: 주말 미포함\n",
    "# make business_days: 주말 미포함\n",
    "Business_days = pd.DataFrame(pd.date_range(start_date, end_date, freq='B'), columns = ['Date'])\n",
    "Business_days['weekday'] = Business_days.Date.apply(lambda x: x.weekday())\n",
    "Business_days['weeknum'] = Business_days.Date.apply(lambda x: x.strftime('%V'))\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# 이 사이에다가 추가하고 싶으신 데이터를 넣으시면 됩니다.\n",
    "\"\"\"\n",
    "# 기존에 사용하던 데이터 - 우선 남겨두고, 영서님께서 해주신 code를 이용해서 했습니다.\n",
    "# KOSPI : 최대한 건들지 않는게 좋을 것 같습니다.\n",
    "KOSPI = fdr.DataReader('KS11', start_date, end_date).reset_index()\n",
    "KOSPI = KOSPI.drop(['Open', 'High', 'Low'], axis=1)\n",
    "cols_rename(KOSPI, 'kospi')\n",
    "data = pd.merge(Business_days, KOSPI, how='outer')\n",
    "\n",
    "# KOSDAQ 추가\n",
    "KOSDAQ = fdr.DataReader('KQ11', start_date, end_date).reset_index()\n",
    "KOSDAQ = KOSDAQ.drop(['Open', 'High', 'Low'], axis=1)\n",
    "cols_rename(KOSDAQ, 'kosdaq')\n",
    "data = pd.merge(data, KOSDAQ, how='outer')\n",
    "\n",
    "# 미국증시: 나스닥(NASDAQ) 추가\n",
    "NAS = fdr.DataReader('NASDAQCOM', start_date, end_date, data_source='fred').reset_index()\n",
    "col_rename(NAS, 'DATE', 'Date')\n",
    "col_rename(NAS, 'NASDAQCOM', 'nasdaq_Close')\n",
    "data = pd.merge(data, NAS, how='outer')\n",
    "\n",
    "# 환율: 원달러(USD) 추가\n",
    "USD = fdr.DataReader('USD/KRW', start_date, end_date).reset_index()\n",
    "USD = USD.drop(['Open', 'High', 'Low'], axis=1)\n",
    "cols_rename(USD, 'usd')\n",
    "data = pd.merge(data, USD, how='outer')\n",
    "\n",
    "# 환율: 원엔(JPY) 추가\n",
    "JPY = fdr.DataReader('JPY/KRW', start_date, end_date).reset_index()\n",
    "JPY = JPY.drop(['Open', 'High', 'Low'], axis=1)\n",
    "cols_rename(JPY, 'jpy')\n",
    "data = pd.merge(data, JPY, how='outer')\n",
    "\n",
    "# 환율: 호주달러/스위스프랑 추가\n",
    "ACF = fdr.DataReader('AUD/CHF', start_date, end_date).reset_index()\n",
    "ACF = ACF.drop(['Open', 'High', 'Low'], axis=1)\n",
    "cols_rename(ACF, 'acf')\n",
    "data = pd.merge(data, ACF, how='outer')\n",
    "\n",
    "#10년 단위 미 국채\n",
    "#US_10 = fdr.DataReader('US10YT=X', start_date, end_date).reset_index()\n",
    "#US_10 = US_10.drop(['Open', 'High', 'Low'], axis=1)\n",
    "# 일~금 데이터만 있고 토요일 데이터는 없기 때문에 해당 부분 반영\n",
    "#cols_rename(US_10, 'us_10')\n",
    "#data = pd.merge(data, US_10, how='outer')\n",
    "\n",
    "# 변동성모델(CBOE에서 제공하는)\n",
    "VIX = fdr.DataReader('VIX', start_date, end_date).reset_index()\n",
    "VIX = VIX.drop(['Open', 'High', 'Low'], axis=1)\n",
    "cols_rename(VIX, 'vix')\n",
    "data = pd.merge(data, VIX, how='outer')\n",
    "\n",
    "\"\"\"\n",
    "# 주중 데이터\n",
    "# KOSPI 추가\n",
    "KOSPI = fdr.DataReader('KS11', start_date, end_date).reset_index()\n",
    "KOSPI.drop(['Open', 'High', 'Low'], axis=1, inplace=True)\n",
    "cols_rename(KOSPI, 'kospi')\n",
    "data = pd.merge(Business_days, KOSPI, how='outer')\n",
    "# KOSDAQ 추가\n",
    "KOSDAQ = fdr.DataReader('KQ11', start_date, end_date).reset_index()\n",
    "KOSDAQ.drop(['Open', 'High', 'Low'], axis=1, inplace=True)\n",
    "cols_rename(KOSDAQ, 'kosdaq')\n",
    "data = pd.merge(data, KOSDAQ, how='outer')\n",
    "# 미국증시: 나스닥(NASDAQ) 추가\n",
    "NAS = fdr.DataReader('NASDAQCOM', start_date, end_date, data_source='fred').reset_index()\n",
    "col_rename(NAS, 'DATE', 'Date')\n",
    "col_rename(NAS, 'NASDAQCOM', 'nasdaq_Close')\n",
    "data = pd.merge(data, NAS, how='outer')\n",
    "# 환율: 원달러(USD) 추가\n",
    "USD = fdr.DataReader('USD/KRW', start_date, end_date).reset_index()\n",
    "USD.drop(['Open', 'High', 'Low'], axis=1, inplace=True)\n",
    "cols_rename(USD, 'usd')\n",
    "data = pd.merge(data, USD, how='outer')\n",
    "# 환율: 원엔(JPY) 추가\n",
    "JPY = fdr.DataReader('JPY/KRW', start_date, end_date).reset_index()\n",
    "JPY.drop(['Open', 'High', 'Low'], axis=1, inplace=True)\n",
    "cols_rename(JPY, 'jpy')\n",
    "data = pd.merge(data, JPY, how='outer')\n",
    "# 환율: 호주달러/스위스프랑 추가\n",
    "ACF = fdr.DataReader('AUD/CHF', start_date, end_date).reset_index()\n",
    "ACF.drop(['Open', 'High', 'Low'], axis=1, inplace=True)\n",
    "cols_rename(ACF, 'acf')\n",
    "data = pd.merge(data, ACF, how='outer')\n",
    "# 국채: 미 국채 10년 추가\n",
    "UGB = fdr.DataReader('DGS10', start_date, end_date, data_source='fred').reset_index()\n",
    "col_rename(UGB, 'DATE', 'Date')\n",
    "col_rename(UGB, 'DGS10', 'ugb_Close')\n",
    "data = pd.merge(data, UGB, how='outer')\n",
    "## 변동성 지수 추가\n",
    "VIX = fdr.DataReader('VIXCLS', start_date, end_date, data_source='fred').reset_index()\n",
    "col_rename(VIX, 'DATE', 'Date')\n",
    "col_rename(VIX, 'VIXCLS', 'vix_Close')\n",
    "data = pd.merge(data, VIX, how='outer')\n",
    "\n",
    "\n",
    "##############################\n",
    "# 주말 데이터\n",
    "# 암호화폐: 비트코인(BitCoin) 추가\n",
    "\n",
    "BTC = fdr.DataReader('BTC/KRW',start_date,end_date).reset_index()\n",
    "BTC['dayofweek'] = BTC['Date'].dt.dayofweek # 요일 (월 = 0)\n",
    "BTC.drop(['Open', 'High', 'Low'], axis=1, inplace=True)\n",
    "cols_rename(BTC, 'btc')\n",
    "\n",
    "# 예외처리: 마지막 데이터가 토요일인 경우\n",
    "if (BTC.loc[len(BTC)-1, 'btc_dayofweek'] == 5):\n",
    "    BTC.drop(len(BTC)-1, inplace=True)\n",
    "\n",
    "# 금토일 데이터를 금요일 데이터로 병합 후 주말 데이터 제거\n",
    "# 금토일 데이터 가중치 >> 1:2:4\n",
    "for idx in BTC.index:\n",
    "    if (BTC.loc[idx, 'btc_dayofweek'] == 6):\n",
    "        BTC.loc[idx-2, 'btc_Close'] = weekendToFriday(BTC, idx-2, 'btc_Close', 'intType')\n",
    "        BTC.loc[idx-2, 'btc_Volume'] = weekendToFriday(BTC, idx-2, 'btc_Volume', 'floatType')\n",
    "        BTC.loc[idx-2, 'btc_Change'] = np.ceil(weekendToFriday(BTC, idx-2, 'btc_Change', 'floatType')*1000)/1000\n",
    "for idx in BTC.index:\n",
    "    if (BTC.loc[idx, 'btc_dayofweek'] == 5 or BTC.loc[idx, 'btc_dayofweek'] == 6):\n",
    "        BTC.drop(idx, inplace=True)\n",
    "\n",
    "# 데이터 가공\n",
    "BTC.drop(['btc_dayofweek'], axis=1, inplace=True)\n",
    "BTC.reset_index(inplace=True)\n",
    "BTC.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "data = pd.merge(data, BTC, how='outer')\n",
    "\n",
    "\n",
    "# 국채: 한국 국채 추가\n",
    "KGB = fdr.DataReader('KR10YT=RR', start_date, end_date).reset_index()\n",
    "KGB['dayofweek'] = KGB['Date'].dt.dayofweek # 요일 (월 = 0)\n",
    "KGB.drop(['Open', 'High', 'Low'], axis=1, inplace=True)\n",
    "cols_rename(KGB, 'kgb')\n",
    "\n",
    "# 예외처리: 마지막 데이터가 토요일인 경우\n",
    "if (KGB.loc[len(KGB)-1, 'kgb_dayofweek'] == 5):\n",
    "    KGB.drop(len(KGB)-1, inplace=True)\n",
    "\n",
    "# 금토일 데이터를 금요일 데이터로 병합 후 주말 데이터 제거\n",
    "# 금토일 데이터 가중치 >> 1:2:4\n",
    "for idx in KGB.index:\n",
    "    if (KGB.loc[idx, 'kgb_dayofweek'] == 6):\n",
    "        KGB.loc[idx-2, 'kgb_Close'] = weekendToFriday(KGB, idx-2, 'kgb_Close', 'floatType')\n",
    "        KGB.loc[idx-2, 'kgb_Change'] = weekendToFriday(KGB, idx-2, 'kgb_Change', 'floatType')\n",
    "        KGB.loc[idx-2, 'kgb_Change'] = np.ceil(weekendToFriday(KGB, idx-2, 'kgb_Change', 'floatType')*1000)/1000\n",
    "for idx in KGB.index:\n",
    "    if (KGB.loc[idx, 'kgb_dayofweek'] == 5 or KGB.loc[idx, 'kgb_dayofweek'] == 6):\n",
    "        KGB.drop(idx, inplace=True)\n",
    "\n",
    "# 데이터 가공\n",
    "KGB.drop(['kgb_dayofweek'], axis=1, inplace=True)\n",
    "KGB.reset_index(inplace=True)\n",
    "KGB.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "data = pd.merge(data, KGB, how='outer')\n",
    "\n",
    "# NaN 값은 전일 값으로 대체. \n",
    "data = data.fillna(method='ffill')\n",
    "data = data.fillna(method='bfill') # 예외처리\n",
    "\n",
    "\n",
    "\n",
    "start_weekday = pd.to_datetime(start_date).weekday()\n",
    "max_weeknum = pd.to_datetime(end_date).strftime('%V')\n",
    "Business_days = pd.DataFrame(pd.date_range(start_date,end_date,freq='B'), columns = ['Date'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "062faf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# 휴장일 데이터에 대해서 처리해야한다.\n",
    "# 휴장일 data는 삭제한다.\n",
    "#kor_NAN_list = data[data['kospi_Close'].isnull()].index\n",
    "#data.drop(set(kor_NAN_list.to_list()), inplace = True)\n",
    "# 휴장일 데이터는 앞의 데이터를 가져온다\n",
    "#print(data.isnull().sum())\n",
    "kor_NAN_list = data[data['kospi_Close'].isnull()].index\n",
    "#en_NAN_list = data[data['vix_Close'].isnull()].index\n",
    "nan_list = data[data.isnull()]\n",
    "#print(kor_NAN_list)\n",
    "#print(nan_list)\n",
    "\n",
    "\n",
    "# learn에 사용할 데이터\n",
    "#train_data = data.drop(['weekday', 'weeknum'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3daa4a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna(method='ffill')\n",
    "data = data.fillna(method='bfill')\n",
    "#nan_list = set(kor_NAN_list.to_list() + en_NAN_list.to_list())\n",
    "#data.drop(nan_list, inplace=True)\n",
    "data[data['kospi_Close'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "91c211cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 368/368 [00:26<00:00, 14.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>2022-05-23</th>\n",
       "      <th>2022-05-24</th>\n",
       "      <th>2022-05-25</th>\n",
       "      <th>2022-05-26</th>\n",
       "      <th>2022-05-27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000060</td>\n",
       "      <td>39750</td>\n",
       "      <td>39700</td>\n",
       "      <td>40800</td>\n",
       "      <td>39800</td>\n",
       "      <td>39800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000080</td>\n",
       "      <td>35350</td>\n",
       "      <td>34950</td>\n",
       "      <td>35900</td>\n",
       "      <td>36150</td>\n",
       "      <td>36250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000100</td>\n",
       "      <td>59600</td>\n",
       "      <td>59100</td>\n",
       "      <td>59700</td>\n",
       "      <td>59900</td>\n",
       "      <td>59800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000120</td>\n",
       "      <td>123000</td>\n",
       "      <td>125500</td>\n",
       "      <td>125500</td>\n",
       "      <td>127500</td>\n",
       "      <td>129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000150</td>\n",
       "      <td>80400</td>\n",
       "      <td>79900</td>\n",
       "      <td>80400</td>\n",
       "      <td>80100</td>\n",
       "      <td>80400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>348210</td>\n",
       "      <td>68400</td>\n",
       "      <td>66500</td>\n",
       "      <td>67000</td>\n",
       "      <td>66300</td>\n",
       "      <td>67000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>352820</td>\n",
       "      <td>221000</td>\n",
       "      <td>215500</td>\n",
       "      <td>219500</td>\n",
       "      <td>214500</td>\n",
       "      <td>218500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>357780</td>\n",
       "      <td>269900</td>\n",
       "      <td>260600</td>\n",
       "      <td>260600</td>\n",
       "      <td>270900</td>\n",
       "      <td>271800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>363280</td>\n",
       "      <td>24500</td>\n",
       "      <td>24400</td>\n",
       "      <td>24550</td>\n",
       "      <td>24600</td>\n",
       "      <td>24400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>950130</td>\n",
       "      <td>17250</td>\n",
       "      <td>16800</td>\n",
       "      <td>16650</td>\n",
       "      <td>16150</td>\n",
       "      <td>16200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index  2022-05-23  2022-05-24  2022-05-25  2022-05-26  2022-05-27\n",
       "0    000060       39750       39700       40800       39800       39800\n",
       "1    000080       35350       34950       35900       36150       36250\n",
       "2    000100       59600       59100       59700       59900       59800\n",
       "3    000120      123000      125500      125500      127500      129000\n",
       "4    000150       80400       79900       80400       80100       80400\n",
       "..      ...         ...         ...         ...         ...         ...\n",
       "365  348210       68400       66500       67000       66300       67000\n",
       "366  352820      221000      215500      219500      214500      218500\n",
       "367  357780      269900      260600      260600      270900      271800\n",
       "368  363280       24500       24400       24550       24600       24400\n",
       "369  950130       17250       16800       16650       16150       16200\n",
       "\n",
       "[370 rows x 6 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################\n",
    "# 특정 model에 대해서, 각 종목별로 학습하는 code 입니다\n",
    "##############################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sample_name = 'sample_submission.csv'\n",
    "sample_submission = pd.read_csv(os.path.join(path, sample_name))\n",
    "true_close = sample_submission.copy()\n",
    "true_close['Index'] = true_close['Index'].apply(lambda x : str(x).zfill(6))\n",
    "\n",
    "\n",
    "day_list = ['2022-05-23', '2022-05-24', '2022-05-25', '2022-05-26', '2022-05-27']\n",
    "\n",
    "\n",
    "i = 0\n",
    "for code in tqdm(stock_list['종목코드'].values):\n",
    "    # 상장폐지된 데이터는 0으로 해야하기 때문에 해당 부분을 더해준다.\n",
    "    while code != true_close.iloc[i]['Index']:\n",
    "        # print(f\"{code}, {true_close.iloc[i]['Index']}\")\n",
    "        i += 1\n",
    "    true_close.iloc[i,1:] = fdr.DataReader(code, start=day_list[0], end = day_list[-1])['Close']\n",
    "    i += 1\n",
    "\n",
    "true_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "393707ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# 특정 model에 대해서, 각 종목별로 학습하는 code 입니다\n",
    "##############################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "submission = sample_submission.copy()\n",
    "submission['Index'] = submission['Index'].apply(lambda x : str(x).zfill(6))\n",
    "day_first = day_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d2b0c8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>2022-05-23</th>\n",
       "      <th>2022-05-24</th>\n",
       "      <th>2022-05-25</th>\n",
       "      <th>2022-05-26</th>\n",
       "      <th>2022-05-27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>348210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>352820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>357780</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>363280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>950130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index  2022-05-23  2022-05-24  2022-05-25  2022-05-26  2022-05-27\n",
       "0    000060           0           0           0           0           0\n",
       "1    000080           0           0           0           0           0\n",
       "2    000100           0           0           0           0           0\n",
       "3    000120           0           0           0           0           0\n",
       "4    000150           0           0           0           0           0\n",
       "..      ...         ...         ...         ...         ...         ...\n",
       "365  348210           0           0           0           0           0\n",
       "366  352820           0           0           0           0           0\n",
       "367  357780           0           0           0           0           0\n",
       "368  363280           0           0           0           0           0\n",
       "369  950130           0           0           0           0           0\n",
       "\n",
       "[370 rows x 6 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "11968f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scale_col = data.columns.to_list()\n",
    "data_scaled = scaler.fit_transform(data[scale_col[3:]])\n",
    "data_scaled = pd.DataFrame(data_scaled)\n",
    "#print(data[scale_col[:3]])\n",
    "data_scaled = pd.merge(data[scale_col[:3]], data_scaled, how='left', left_index=True, right_index=True)\n",
    "data_scaled.columns = scale_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8c0650c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 368/368 [25:18<00:00,  4.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# 종목별로 사용할 데이터 작성\n",
    "\n",
    "ind_code = 0\n",
    "\n",
    "# 데이터 정리\n",
    "indasdf = 0\n",
    "for code in tqdm(stock_list['종목코드'].values):\n",
    "    #print(code)\n",
    "    \n",
    "    # x에 대해서 작성\n",
    "    # 1주전의 데이터(월요일이라면, 저번주 월~금, 화요일이라면, 저번주 화~월)를 사용하고, \n",
    "    # x와 y index가 같더라도 y[x_index+1]을 답으로 삼기 때문에, 1, 2, 3, 4일 전 데이터를 사용하면 된다.\n",
    "    \n",
    "    # ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Change']\n",
    "    code_data = fdr.DataReader(code, start = start_date, end = end_date).reset_index()   \n",
    "    #code_data = code_data.drop(['Open', 'High', 'Low'], axis=1)\n",
    "    code_data = pd.merge(Business_days, code_data, how='outer')\n",
    "    #code_data = code_data[code_data['Close'].notna()]\n",
    "    \n",
    "    # NAN이 아닌 첫 index를 찾는다.\n",
    "    \n",
    "    #이동 평균선 추가: 5, 10, 20, 60일(1주 전)\n",
    "    #code_data['5_close'] = code_data['Close'].rolling(window=5).mean()   \n",
    "    #code_data['10_close'] = code_data['Close'].rolling(window=10).mean()   \n",
    "    #code_data['20_close'] = code_data['Close'].rolling(window=20).mean()\n",
    "    #code_data['60_close'] = code_data['Close'].rolling(window=60).mean() \n",
    "    \n",
    "    \n",
    "    #df = pd.merge(data, code_data, how='left', on='Date')\n",
    "    df = pd.merge(data_scaled, code_data, how='left', on='Date')\n",
    "    \n",
    "    #df['weekday'] = df.Date.apply(lambda x : x.weekday())\n",
    "    #df['weeknum'] = df.Date.apply(lambda x : x.strftime('%V'))\n",
    "    for i in range(1, 5):\n",
    "        df[f'Close_{i}d_bef'] = df['Close'].shift(i)    \n",
    "    \n",
    "    #print(pd.isna(df.to_numpy()).sum())\n",
    "    df = df.ffill()\n",
    "    #df = df.bfill()\n",
    "    \n",
    "    # 만약 KOSPI면, kosdaq 관련 내용 drop\n",
    "    # 만약 이걸 drop하지 않으면 결과가 어떨까? \n",
    "\n",
    "    market = stock_list[stock_list['종목코드'].str.contains(code)]['상장시장'].values[0]\n",
    "    if market == 'KOSPI':\n",
    "        df = df.drop(['kosdaq_Close', 'kosdaq_Volume', 'kosdaq_Change'], axis=1)\n",
    "    else:\n",
    "        df = df.drop(['kospi_Close', 'kospi_Volume', 'kospi_Change'], axis=1)\n",
    "\n",
    "    # code_data = code_data[code_data['Close'].notna()]\n",
    "    # Business day의 시작 날짜보다, 상장한 날짜가 더 느린 경우를 생각하기 위해, close 기준으로 앞 부분 다 빼주기    \n",
    "    df = df[df['Close'].notna()]\n",
    "    \n",
    "    #print(df.iloc[5:].isna().sum())\n",
    "    # 날짜, 몇번째 주인지는 의미 없을듯 하고, 요일정도는 의미가 있지 않을까? weekday도 뺴자\n",
    "    df = df.drop(['Date','weekday'], axis=1)\n",
    "    #df = df.drop(['Date','weekday'], axis=1)\n",
    "    #df = df.drop(['Date'], axis=1)\n",
    "\n",
    "    x_data = df.to_numpy()\n",
    "    #print(pd.isna(x_data[5:]).sum())\n",
    "    #print(x_data.shape)\n",
    "\n",
    "    # 이제 학습을 진행한다\n",
    "    #print(df.columns.to_list())\n",
    "    #break\n",
    "    \n",
    "    xgb_dict = dict()\n",
    "    \n",
    "    for name in df.columns.to_list():\n",
    "        xgb_dict[name] = XGBRegressor(eta = 0.10, subsample=0.8)\n",
    "        \n",
    "        \n",
    "    # y값의 [-1]: 5일전, [-2]: 4일전, [-3]: 3일전, [-2]: 2일전, ['Close']: 하루전->예측된다\n",
    "    # 다만 돌리다보면 어느정도 확정되는 값이 존재하기 때문에, 해당 부분은 어느정도 감안해야한다.\n",
    "    # ['kospi_Close', 'kospi_Volume', 'kospi_Change', 'nasdaq_Close','usd_Close',\n",
    "    #  'usd_Change', 'jpy_Close', 'jpy_Change', 'acf_Close','acf_Change',\n",
    "    #  'ugb_Close', 'vix_Close', 'Open', 'High', 'Low',\n",
    "    #  'Close','Volume', 'Change', 'Close_2d_bef', 'Close_3d_bef',\n",
    "    #  'Close_4d_bef','Close_5d_bef'],\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ind_close = df.columns.to_list().index('Close')\n",
    "    #ind_weekday = df.columns.to_list().index('weekday')\n",
    "    #ind_weeknum = df.columns.to_list().index('weeknum')\n",
    "    predict_Close = []\n",
    "    \n",
    "    # 금요일 종가에 대한 비율을 계산해서 예측해보자.\n",
    "    \n",
    "\n",
    "    # 첫째날(월요일)\n",
    "    ind_ = 0\n",
    "    list_ = []\n",
    "    for col_type in df.columns.to_list():\n",
    "        xgb_dict[col_type].fit(x_data[5:-1], x_data[6:, ind_])\n",
    "        ind_ += 1\n",
    "        predict = xgb_dict[col_type].predict(np.array([x_data[-1]]))\n",
    "        list_.append(predict[0])\n",
    "    list_ = np.array(list_)\n",
    "    predict_Close.append(list_[ind_close])\n",
    "   \n",
    "\n",
    "    # 둘째날\n",
    "    list_input = list_\n",
    "    list_output = []\n",
    "    # 예측한 것 중에서, 2~5일정도 예측했기 때문에, 실제 데이터를 넣어준다.\n",
    "    list_input[-1] = x_data[-1][-2]\n",
    "    list_input[-2] = x_data[-1][-3]\n",
    "    list_input[-3] = x_data[-1][-4]\n",
    "    list_input[-4] = x_data[-1][ind_close]\n",
    "    # weekday\n",
    "    #list_input[ind_weekday] = 0 # 월요일\n",
    "    # weeknum\n",
    "    #list_input[ind_weeknum] = str(int(x_data[-1][ind_weeknum])+1)\n",
    "            \n",
    "    # 이제 예측한다\n",
    "    for col_type in df.columns.to_list():\n",
    "        predict = xgb_dict[col_type].predict([list_input])\n",
    "        list_output.append(predict[0])\n",
    "    list_output = np.array(list_output)\n",
    "    predict_Close.append(list_output[ind_close])\n",
    "    \n",
    "    for i in range(3):\n",
    "        # 셋째, 넷째, 다섯째날\n",
    "        list_output[-1] = list_input[-2]\n",
    "        list_output[-2] = list_input[-3]\n",
    "        list_output[-3] = list_input[-4]\n",
    "        list_output[-4] = list_input[ind_close]\n",
    "        list_input = list_output\n",
    "        list_output = []\n",
    "        # 이제 예측한다\n",
    "        for col_type in df.columns.to_list():\n",
    "            predict = xgb_dict[col_type].predict([list_input])\n",
    "            list_output.append(predict[0])\n",
    "        list_output = np.array(list_output)\n",
    "        predict_Close.append(list_output[ind_close])\n",
    "    \n",
    "    ind_ = 0\n",
    "    predict_Close = np.asarray(predict_Close, dtype = int)\n",
    "    \n",
    "    while submission.iloc[ind_code]['Index'] != code:\n",
    "        ind_code += 1\n",
    "        \n",
    "    submission.iloc[ind_code, 1:] = predict_Close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "06d7ba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6398563060689253\n",
      "1942.6794594594594\n"
     ]
    }
   ],
   "source": [
    "#np.mean(np.mean(np.abs(submission[5:] - true_close[5:]) / true_close[5:]))*100: 잘못된 수식입니다. 호용님 code대로 했습니다.\n",
    "# 호용님 code: print(diff / np.sum(list(test_y.values())))\n",
    "submission_result = submission[submission.columns[1:]].to_numpy()\n",
    "true_close_result = true_close[true_close.columns[1:]].to_numpy()\n",
    "\n",
    "print(np.sum(np.sum(np.abs(submission_result- true_close_result)))/np.sum(np.sum(true_close_result))*100)\n",
    "print(np.mean(np.abs(submission_result - true_close_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8551cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0cdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
